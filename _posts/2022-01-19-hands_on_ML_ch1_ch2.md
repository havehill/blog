---
title : "핸즈 온 머신러닝 ch1, ch2 정리"
excerpt : "boaz 맨맨 week 0 assignment"

categories : 
- Post
tags:
- []

toc : true
toc_sticky : true

date : 2022-01-19
last_modified_at : 2022-01-19
---

# Ch1. 한 눈에 보는 머신러닝


## 1.4 머신러닝 시스템의 종류

### 1.4.1 지도 학습과 비지도 학습

- 지도 학습 : 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함됨  
ex) 분류, 예측 (타깃 수치 예측)

- 비지도 학습 : 훈련 데이터에 레이블이 없음.   
ex)군집, 시각화와 차원 축소, 연관 규칙 학습

- 준지도 학습 : 일부만 레이블이 있는 데이터.  
ex) 심층 신뢰 신경망, 제한된 볼츠만 머신

- 강화 학습 : 학습하는 시스템을 에이젼트라고 부르며, 환경을 관찰해서 행동을 실행하고 그 결과로 부정적인 보상에 해당하는 벌점을 받음. 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습함.   
ex) 보행 로봇, 알파고


### 1.4.2 배치 학습과 온라인 학습

입력 데이터의 스트림부터 점진적으로 학습할 수 있나? 

- 배치 학습 : 시스템이 점진적으로 학습할 수 없음. 가용한 데이터를 모두 사용해 훈련시켜야 함. 오프라인 학습이라고도 함. 

- 온라인 학습 : 데이터를 순차적으로 한 개 또는 미니배치라고 불리는 작은 묶음 단위로 주입하여 시스템을 훈련함. 

### 1.4.3 사례 기반 학습과 모델 기반 학습

어떻게 일반화가 되는가?

-  사례 기반 학습 : 단순히 기억하는 것. 예를 들어, 스팸 메일과 매우 유사한 메일을 구분하는 경우, 두 메일 사이의 유사도를 측정한 후 스팸 메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 처리함. 

- 모델 기반 학습 : 샘플들의 모델을 만들어 예측에 사용하는 것. 

## 1.5 머신러닝의 주요 도전 과제

### 1.5.1 충분하지 않은 양의 훈련 데이터
대부분의 머신러닝이 잘 작동하려면 데이터가 많아야 함.

### 1.5.2 대표성 없는 훈련 데이터 
일반화가 잘 되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요함. 

### 1.5.3 낮은 품질의 데이터 
에러, 이상치, 잡음 같은 불순 요소를 정제해야 함. 

### 1.5.4 관련 없는 특성
특성 선택, 특성 추출의 단계가 필요함 

## 1.5.5 훈련 데이터 과대적합
'규제'를 통하여 과대적합을 방지하자. ex) 릿지, 라쏘 회귀

## 1.5.6 훈련 데이터 과소적합
모델이 너무 단순해서 데이터의 내제된 구조를 학습하지 못 할 때.


## 1.6 테스트와 검증

데이터를 훈련 세트와 테스트 세트 두 개로 나눔. 새로운 샘플에 대한 오류율을 일반화 오차라고 함.

### 1.6.1 하이퍼파라미터 튜닝과 모델 선택 
일반화 오차를 테스트 세트에서 여러 번 측정하면 테스트 세트에 최적화된 모델을 만들어, 실제 서비스에 투입 시 성능이 좋지 않을 수 있음. 
-> 홀드아웃 검증, 교차 검증

